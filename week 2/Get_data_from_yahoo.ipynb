{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f479ba8",
   "metadata": {},
   "source": [
    "# Basic Backtester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c60222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc176b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fc6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all imp lib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly \n",
    "import yfinance as yf\n",
    "import time\n",
    "# etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7f4843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price            Close        High         Low        Open    Volume\n",
      "Ticker            AAPL        AAPL        AAPL        AAPL      AAPL\n",
      "Date                                                                \n",
      "2023-11-01  172.478012  172.735777  168.661024  169.533482  56934900\n",
      "2023-11-02  176.047150  176.255340  173.955245  174.014728  77334800\n",
      "2023-11-03  175.135025  175.303580  171.863338  172.745705  79763700\n",
      "2023-11-06  177.692917  177.891199  174.698827  174.867368  63841300\n",
      "2023-11-07  180.260696  180.875374  177.435132  177.643323  70530000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example of a stock's data\n",
    "apple_data = yf.download(\"AAPL\", start=\"2023-11-01\", end=\"2024-05-01\")\n",
    "\n",
    "print(apple_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'AAPL', 'ABBV', 'ABNB', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM']\n"
     ]
    }
   ],
   "source": [
    "# Load list of S&P 500 companies from Wikipedia\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "table = pd.read_html(url) # returns a dataframe\n",
    "sp500_df = table[0]  # 1st table\n",
    "tickers = sp500_df['Symbol'].tolist()  # List of S&P 500 tickers\n",
    "tickers.sort()\n",
    "print(tickers[:10])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eeac68",
   "metadata": {},
   "source": [
    "Now we can use these tickers to get the data.\n",
    "\n",
    "\n",
    "Note : Yahoo Finance might block or throttle requests if you fetch too many tickers in bulk. Break it into small batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a95f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to download data of all the tickers in batches of 10, returns a dict storing {ticker : corresponding data}\n",
    "# Also this code senses the data which are not downloadable and delete them from tickers list\n",
    "def download_sp500_data(tickers, start=\"2020-01-01\", end=\"2024-01-01\"):\n",
    "    all_data = {}\n",
    "    failed_tickers = []\n",
    "    batch_size = 10\n",
    "    for i in range(0, len(tickers), batch_size):\n",
    "        batch = tickers[i:i+batch_size]\n",
    "        print(f\"Downloading batch {i//batch_size + 1}: {batch}\")  # 1/10 = 0.1 while 1//10 = 0\n",
    "        try:\n",
    "            data = yf.download(batch, start=start, end=end, group_by='ticker', threads=True)\n",
    "            for ticker in batch:\n",
    "                # Check whether the data is structured correctly\n",
    "                if isinstance(data.columns, pd.MultiIndex) and ticker in data.columns.levels[0]:  # if data is pd.MultiIndex then deal with it\n",
    "                    all_data[ticker] = data[ticker]\n",
    "                elif isinstance(data, dict) and ticker in data: # if data is dict then deal with it\n",
    "                    all_data[ticker] = data[ticker]\n",
    "                else:\n",
    "                    failed_tickers.append(ticker)\n",
    "        except Exception as e:\n",
    "            print(f\"Batch error: {e}\")\n",
    "            failed_tickers.extend(batch)\n",
    "        time.sleep(1)\n",
    "    return all_data, failed_tickers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64df77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing data into csv, as , {ticker}.csv : ticker tell the corresponding stock name\n",
    "def save_data_to_csv(data_dict):\n",
    "    for ticker, df in data_dict.items():\n",
    "        filename = f\"{ticker}.csv\"\n",
    "        df.to_csv(filename)\n",
    "        print(f\"Saved {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f37b4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "\n",
    "sp500_data , failed = download_sp500_data(tickers)\n",
    "save_data_to_csv(sp500_data)                                    # Downloading data. Might take a while and might take a lot of time.\n",
    "\n",
    "###################################################################################\n",
    "\n",
    "tickers = [t for t in tickers if t not in failed]               # Remove tickers that failed to download. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ea2302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the ticker names\n",
    "\n",
    "t = pd.DataFrame(tickers)\n",
    "\n",
    "t.to_csv(\"Tickers.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
